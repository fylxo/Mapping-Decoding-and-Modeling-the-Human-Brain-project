{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T16:03:04.413163Z",
     "start_time": "2025-02-15T16:03:02.437944Z"
    }
   },
   "source": [
    "import my_functions as myfun\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pywt\n",
    "import cv2\n",
    "from skimage.filters import gabor\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from scipy.signal import convolve\n",
    "from itertools import product\n",
    "from sklearn.manifold import MDS\n",
    "from scipy.io import loadmat\n",
    "from numpy.linalg import lstsq\n",
    "from scipy.stats import t"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "be48c1d2-30f5-45f6-9a4e-517db171dc42",
   "metadata": {},
   "source": [
    "## Project Work 5: vRF Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b5ce22-6be9-43bc-b0b9-b4163a2018ac",
   "metadata": {},
   "source": [
    "## Load previous data necessary for this assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "311f5b76-e718-4c26-b7bd-60c93b8306ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the NIfTI file\n",
    "bold_path = \"subj1/bold.nii.gz\"\n",
    "bold_img = nib.load(bold_path)\n",
    "\n",
    "# Extract the data as a NumPy array\n",
    "bold_data = bold_img.get_fdata()\n",
    "\n",
    "# Load the labels into a pandas DataFrame\n",
    "labels = pd.read_csv(\"subj1/labels.txt\", sep=\" \", header=0, names=[\"Condition\", \"Run\"])\n",
    "\n",
    "# Get unique conditions from labels\n",
    "unique_conditions = [condition for condition in labels[\"Condition\"].unique() if condition != \"rest\"]\n",
    "\n",
    "# Create the design matrix\n",
    "design_matrix = myfun.create_design_matrix(labels)\n",
    "\n",
    "# Modify the convolved matrix\n",
    "design_matrix_with_intercepts  = myfun.add_run_intercepts(design_matrix, labels)\n",
    "\n",
    "# Load the HRF file\n",
    "hrf_path = \"hrf.mat\"  \n",
    "hrf_data = loadmat(hrf_path)\n",
    "hrf_sampled = hrf_data.get(\"hrf_sampled\", None).flatten()  # Downsampled HRF\n",
    "\n",
    "convolved_matrix = myfun.convolve_conditions(design_matrix_with_intercepts, hrf_sampled)\n",
    "\n",
    "# load design matrix as \"convolved_matrix\"\n",
    "X = convolved_matrix.values\n",
    "df = X.shape[0] - np.linalg.matrix_rank(X)\n",
    "\n",
    "# Fit the GLM and get results\n",
    "residuals, beta_maps = myfun.fit_glm_and_generate_beta_maps(bold_data, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75df597f-aa84-4095-84a4-720516b521da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ROI masks\n",
    "vt_mask_path = \"subj1/mask4_vt.nii.gz\"\n",
    "face_mask_path = \"subj1/mask8_face_vt.nii.gz\"\n",
    "house_mask_path = \"subj1/mask8_house_vt.nii.gz\"\n",
    "\n",
    "vt_mask = nib.load(vt_mask_path).get_fdata() > 0  # Ventral Temporal ROI\n",
    "face_mask = nib.load(face_mask_path).get_fdata() > 0  # Face ROI\n",
    "house_mask = nib.load(house_mask_path).get_fdata() > 0  # House ROI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b2b96f-547a-4520-9b47-27a49a9cb9b1",
   "metadata": {},
   "source": [
    "### Task: vRF modeling of fMRI data\n",
    "\n",
    "- How would you start implementing a voxel receptive field model?\n",
    "- The Haxby data is not optimal for vRF fitting. Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40649889-fd71-442e-b9e1-a90f8931d0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_wavelet_features(image, wavelet='haar', level=2):\n",
    "    \"\"\"\n",
    "    Extract wavelet features from an image.\n",
    "    \"\"\"\n",
    "    coeffs = pywt.wavedec2(image, wavelet, level=level)\n",
    "    features = []\n",
    "\n",
    "    for coeff in coeffs:\n",
    "        if isinstance(coeff, tuple):\n",
    "            # Detail coefficients (horizontal, vertical, diagonal)\n",
    "            for c in coeff:\n",
    "                features.append(np.mean(c))\n",
    "                features.append(np.std(c))\n",
    "        else:\n",
    "            # Approximation coefficients\n",
    "            features.append(np.mean(coeff))\n",
    "            features.append(np.std(coeff))\n",
    "\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a615e48-14e2-49e9-9f8e-7fc44b2a82e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_extract_wavelet_features(stimuli_folder, wavelet='haar', level=2):\n",
    "    \"\"\"\n",
    "    Load all images from the stimuli folder and extract Wavelet features.\n",
    "    \"\"\"\n",
    "    \n",
    "    all_features = []\n",
    "    categories = [d for d in os.listdir(stimuli_folder) if os.path.isdir(os.path.join(stimuli_folder, d))]\n",
    "\n",
    "    for category in categories:\n",
    "        category_path = os.path.join(stimuli_folder, category)\n",
    "        for file_name in os.listdir(category_path):\n",
    "            file_path = os.path.join(category_path, file_name)\n",
    "\n",
    "            if not os.path.isfile(file_path):\n",
    "                continue\n",
    "\n",
    "            image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            if image is None:\n",
    "                print(f\"Warning: Failed to load image {file_path}\")\n",
    "                continue\n",
    "\n",
    "            # Normalize\n",
    "            image = image / 255.0\n",
    "            features = extract_wavelet_features(image, wavelet, level)\n",
    "            all_features.append(features)\n",
    "\n",
    "    return np.array(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b76ffdae-cc9d-40f1-b759-ec207d948f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted wavelet features shape: (335, 14)\n"
     ]
    }
   ],
   "source": [
    "# Apply wavelet feature extraction\n",
    "stimuli_folder = \"stimuli\"\n",
    "wavelet_features = load_and_extract_wavelet_features(stimuli_folder)\n",
    "\n",
    "print(f\"Extracted wavelet features shape: {wavelet_features.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53df49aa-a82e-434a-be82-b5a8a73918ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition\n",
      "rest            588\n",
      "scissors        108\n",
      "face            108\n",
      "cat             108\n",
      "shoe            108\n",
      "house           108\n",
      "scrambledpix    108\n",
      "bottle          108\n",
      "chair           108\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each condition in the labels file\n",
    "condition_counts = labels[\"Condition\"].value_counts()\n",
    "print(condition_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa5b17ed-e4cc-4f60-994d-b99cb372765d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images in stimuli : 663\n",
      "Total images in controls: 328\n"
     ]
    }
   ],
   "source": [
    "stimuli_folder = \"stimuli\"\n",
    "controls_folder = os.path.join(stimuli_folder, \"controls\")\n",
    "\n",
    "# Count total images\n",
    "stimuli_count = sum([len(files) for _, _, files in os.walk(stimuli_folder) if \"controls\" not in _])\n",
    "controls_count = sum([len(files) for _, _, files in os.walk(controls_folder)])\n",
    "\n",
    "print(f\"Total images in stimuli : {stimuli_count}\")\n",
    "print(f\"Total images in controls: {controls_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c61b6331-1b46-4b25-a77b-2daee07404f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolve Gabor features with HRF\n",
    "def convolve_with_hrf(features, hrf):\n",
    "    \"\"\"\n",
    "    Convolve features with the HRF.\n",
    "    Args:\n",
    "        features (numpy.ndarray): Design matrix (rows = images, cols = Gabor features).\n",
    "        hrf (numpy.ndarray): Hemodynamic Response Function.\n",
    "    Returns:\n",
    "        convolved_features (numpy.ndarray): Convolved design matrix.\n",
    "    \"\"\"\n",
    "    convolved_features = np.zeros_like(features)\n",
    "    for col in range(features.shape[1]):  # Convolve each feature column\n",
    "        convolved_features[:, col] = convolve(features[:, col], hrf, mode='full')[:features.shape[0]]\n",
    "    return convolved_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9f97982-0b49-4cfb-956c-4bd264f56023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolved design matrix shape: (335, 14)\n"
     ]
    }
   ],
   "source": [
    "# Apply HRF convolution\n",
    "convolved_design_matrix = convolve_with_hrf(wavelet_features, hrf_sampled)\n",
    "print(f\"Convolved design matrix shape: {convolved_design_matrix.shape}\")  # Expected: (1452, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2069079-e25c-4217-82fb-0ba5749ca9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_vrf_model(voxel_data, design_matrix):\n",
    "    beta_weights = np.linalg.pinv(design_matrix.T @ design_matrix) @ design_matrix.T @ voxel_data\n",
    "    return beta_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0661b0e5-99c2-4cb4-915b-0b8085bb7189",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1452 is different from 335)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[28], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m vt_voxel_data \u001B[38;5;241m=\u001B[39m bold_data[vt_mask]  \u001B[38;5;66;03m# Shape: (577, 1452)\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Fit the vRF Model\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m beta_weights \u001B[38;5;241m=\u001B[39m fit_vrf_model(vt_voxel_data\u001B[38;5;241m.\u001B[39mT, convolved_design_matrix)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitted vRF model. Beta weights shape: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbeta_weights\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[27], line 2\u001B[0m, in \u001B[0;36mfit_vrf_model\u001B[1;34m(voxel_data, design_matrix)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit_vrf_model\u001B[39m(voxel_data, design_matrix):\n\u001B[1;32m----> 2\u001B[0m     beta_weights \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39mpinv(design_matrix\u001B[38;5;241m.\u001B[39mT \u001B[38;5;241m@\u001B[39m design_matrix) \u001B[38;5;241m@\u001B[39m design_matrix\u001B[38;5;241m.\u001B[39mT \u001B[38;5;241m@\u001B[39m voxel_data\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m beta_weights\n",
      "\u001B[1;31mValueError\u001B[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1452 is different from 335)"
     ]
    }
   ],
   "source": [
    "# Extract voxel data from the ventral temporal ROI\n",
    "vt_voxel_data = bold_data[vt_mask]  # Shape: (577, 1452)\n",
    "\n",
    "# Fit the vRF Model\n",
    "beta_weights = fit_vrf_model(vt_voxel_data.T, convolved_design_matrix)\n",
    "\n",
    "print(f\"Fitted vRF model. Beta weights shape: {beta_weights.shape}\")  # Expected: (16, 577)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db2f9de-030d-4dca-b11d-c24a48c451ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
